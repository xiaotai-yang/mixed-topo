{
 "cells": [
  {
   "cell_type": "code",
   "id": "63dad47a3ef7b959",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:03.488925Z",
     "start_time": "2025-04-18T23:16:03.311871Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from itertools import chain\n",
    "import string\n",
    "from functools import partial\n",
    "from jax import config, lax\n",
    "from util import *\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "n = 4\n",
    "setA, setB, setC = plot_regions(n)\n",
    "plaq_ABC, plaq_C, plaq_BC, plaq_AC = plaq_ABC_func(n), plaq_C_func(n), plaq_BC_func(n), plaq_AC_func(n)\n",
    "plaq_B = plaq_B_func(n)\n",
    "\n",
    "plaq_ABC_dict = [ dict.fromkeys(row, 0) for row in plaq_ABC ]\n",
    "plaq_B_dict = [ dict.fromkeys(row, 0) for row in plaq_B ]\n",
    "plaq_C_dict = [dict.fromkeys(row, 0) for row in plaq_C ]\n",
    "plaq_BC_dict = [ dict.fromkeys(row, 0) for row in plaq_BC ]\n",
    "plaq_AC_dict = [ dict.fromkeys(row, 0) for row in plaq_AC ]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 700x700 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setA: {((8, 7), 'V'), ((11, 3), 'H'), ((11, 5), 'V'), ((10, 7), 'V'), ((8, 9), 'V'), ((11, 4), 'V'), ((9, 10), 'V'), ((10, 8), 'H'), ((10, 9), 'V'), ((8, 3), 'V'), ((9, 4), 'H'), ((8, 2), 'V'), ((9, 6), 'V'), ((10, 4), 'V'), ((9, 5), 'V'), ((8, 5), 'V'), ((11, 7), 'V'), ((10, 6), 'H'), ((8, 4), 'V'), ((11, 6), 'V'), ((10, 3), 'H'), ((9, 7), 'V'), ((10, 5), 'V'), ((9, 2), 'H'), ((9, 9), 'H'), ((8, 10), 'V'), ((10, 2), 'H'), ((11, 8), 'V'), ((9, 8), 'V'), ((9, 10), 'H'), ((11, 5), 'H'), ((8, 6), 'V'), ((9, 3), 'V'), ((10, 7), 'H'), ((11, 4), 'H'), ((8, 8), 'V'), ((10, 9), 'H'), ((9, 6), 'H'), ((10, 8), 'V'), ((10, 4), 'H'), ((9, 5), 'H'), ((8, 1), 'V'), ((11, 7), 'H'), ((8, 11), 'V'), ((11, 6), 'H'), ((9, 4), 'V'), ((9, 7), 'H'), ((10, 5), 'H'), ((11, 8), 'H'), ((10, 6), 'V'), ((9, 1), 'H'), ((10, 3), 'V'), ((9, 8), 'H'), ((9, 2), 'V'), ((9, 9), 'V'), ((9, 3), 'H')}\n",
      "setB: {((3, 5), 'H'), ((1, 6), 'H'), ((1, 5), 'V'), ((3, 7), 'H'), ((0, 7), 'V'), ((1, 7), 'V'), ((2, 5), 'H'), ((2, 4), 'H'), ((1, 4), 'H'), ((2, 7), 'H'), ((1, 5), 'H'), ((3, 6), 'V'), ((3, 5), 'V'), ((2, 6), 'V'), ((1, 7), 'H'), ((1, 6), 'V'), ((0, 6), 'V'), ((3, 7), 'V'), ((3, 4), 'H'), ((2, 5), 'V'), ((2, 7), 'V'), ((0, 5), 'V'), ((2, 6), 'H'), ((3, 6), 'H')}\n",
      "setC: {((5, 2), 'H'), ((4, 8), 'H'), ((4, 3), 'H'), ((4, 10), 'H'), ((4, 9), 'V'), ((8, 1), 'H'), ((2, 3), 'V'), ((6, 10), 'H'), ((1, 8), 'V'), ((6, 1), 'V'), ((2, 2), 'H'), ((4, 9), 'H'), ((7, 8), 'H'), ((8, 3), 'H'), ((8, 2), 'H'), ((3, 1), 'V'), ((6, 2), 'V'), ((3, 3), 'V'), ((4, 11), 'V'), ((6, 11), 'H'), ((1, 3), 'H'), ((1, 9), 'V'), ((7, 1), 'V'), ((8, 8), 'H'), ((5, 1), 'H'), ((7, 10), 'H'), ((7, 9), 'H'), ((8, 11), 'H'), ((2, 8), 'V'), ((5, 9), 'V'), ((7, 11), 'H'), ((3, 2), 'V'), ((2, 10), 'V'), ((3, 4), 'V'), ((5, 3), 'H'), ((4, 1), 'V'), ((6, 0), 'H'), ((5, 11), 'V'), ((7, 2), 'V'), ((8, 9), 'H'), ((4, 2), 'V'), ((3, 8), 'V'), ((2, 3), 'H'), ((2, 9), 'V'), ((8, 10), 'H'), ((6, 9), 'V'), ((4, 1), 'H'), ((5, 11), 'H'), ((6, 3), 'V'), ((1, 8), 'H'), ((6, 1), 'H'), ((0, 8), 'V'), ((3, 9), 'V'), ((5, 8), 'H'), ((3, 1), 'H'), ((6, 2), 'H'), ((7, 3), 'V'), ((3, 3), 'H'), ((4, 11), 'H'), ((3, 11), 'V'), ((0, 4), 'V'), ((7, 1), 'H'), ((7, 0), 'H'), ((5, 10), 'V'), ((5, 2), 'V'), ((2, 8), 'H'), ((5, 9), 'H'), ((4, 3), 'V'), ((3, 2), 'H'), ((4, 0), 'H'), ((6, 8), 'H'), ((1, 4), 'V'), ((5, 10), 'H'), ((8, 0), 'H'), ((7, 2), 'H'), ((6, 10), 'V'), ((4, 2), 'H'), ((3, 8), 'H'), ((2, 2), 'V'), ((2, 9), 'H'), ((6, 9), 'H'), ((6, 3), 'H'), ((3, 10), 'V'), ((6, 11), 'V'), ((1, 3), 'V'), ((3, 9), 'H'), ((5, 1), 'V'), ((7, 3), 'H'), ((7, 10), 'V'), ((7, 9), 'V'), ((4, 10), 'V'), ((7, 11), 'V'), ((3, 10), 'H'), ((2, 4), 'V'), ((5, 3), 'V'), ((5, 0), 'H')}\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "def flip_one_free(plaq_zero):\n",
    "    # if plaq_zero is a dict-of-dicts:\n",
    "    plaq = copy.deepcopy(plaq_zero)\n",
    "    i = random.choice([i for i in range (len(plaq_zero))])\n",
    "    # if it’s a list-of-dicts, you’d do:\n",
    "    # i = random.randrange(len(plaq_zero))\n",
    "    \n",
    "    inner_keys = list(plaq_zero[i].keys())\n",
    "    k = random.choice(inner_keys)\n",
    "    \n",
    "    # flip 0↔1\n",
    "    plaq[i][k] = 1 - plaq_zero[i][k]\n",
    "    \n",
    "    return plaq\n",
    "\n",
    "def is_on_hole_boundary(coord, n, kind=\"ABC\"):\n",
    "    \"\"\"\n",
    "    coord:  (r, c)\n",
    "    n:      lattice parameter\n",
    "    kind:   either \"ABC\" or \"AB\"\n",
    "    returns True if coord lies on the forbidden ring\n",
    "    for the given kind of plaquette.\n",
    "    \"\"\"\n",
    "    r, c = coord\n",
    "\n",
    "    # ---- these three edges are common to both AB and ABC ----\n",
    "    # right edge       c = 2*n,  r in [n .. 2*n-1]\n",
    "    # left edge        c = n-1,  r in [n .. 2*n-1]\n",
    "    # bottom edge      r = 2*n, c in [n+1 .. 2*n-1]\n",
    "    if (n <= r <= 2*n-1 and c == 2*n) or \\\n",
    "       (n <= r <= 2*n-1 and c == n-1) or \\\n",
    "       (r == 2*n   and n+1 <= c <= 2*n-1):\n",
    "        return True\n",
    "\n",
    "    # ---- the only difference is the “top” segment ----\n",
    "    if kind.upper() == \"ABC\":\n",
    "        # single horizontal strip at r = n-1\n",
    "        return (r == n-1 and n <= c <= 2*n-1)\n",
    "    else:\n",
    "        # two vertical strips at c = n or c = 2*n-1\n",
    "        # for r = 1 .. n-1\n",
    "        return (1 <= r <= n-1 and (c == n or c == 2*n-1))\n",
    "\n",
    "\n",
    "def flip_one(plaq_zero, n, kind=\"ABC\"):\n",
    "    \"\"\"\n",
    "    Randomly choose (i, coord) in plaq_zero; if coord is NOT on\n",
    "    the forbidden hole‑boundary (of the given kind), flip it.\n",
    "    \"\"\"\n",
    "    plaq = copy.deepcopy(plaq_zero)\n",
    "    while True:\n",
    "        i = random.choice([i for i in range (len(plaq_zero))])\n",
    "        choices = list(plaq_zero[i].keys())\n",
    "        k = random.choice(choices)\n",
    "        if not is_on_hole_boundary(k, n, kind):\n",
    "            plaq[i][k] = 1 - plaq_zero[i][k]\n",
    "            return plaq\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:03.785268Z",
     "start_time": "2025-04-18T23:16:03.768267Z"
    }
   },
   "id": "6c7753e2ccca6ef",
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": [
    "def initial_top_ABC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Build a list of n tensors corresponding to the top row.\n",
    "    The leftmost and rightmost are boundary incomplete (shape (2,2)),\n",
    "    while the ones in between are boundary full (shape (2,2,2)).\n",
    "    \"\"\"\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_edge_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "def seq_ABC(n, plaq_dict, plaq, p):\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_edge_tensor(m, p))  # right boundary, shape (2,2,2)\n",
    "    return tensor_list\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_initial_ABC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Contract a list of n top-boundary tensors from left to right.\n",
    "    The free vertical indices remain, and internal (horizontal) indices are contracted.\n",
    "    \"\"\"\n",
    "    # Define labels for the indices.\n",
    "    label = string.ascii_letters\n",
    "    # Initialize the tensor list.\n",
    "    tensor_list = initial_top_ABC(n, plaq_dict, plaq, p)\n",
    "    '''\n",
    "     0 - - n\n",
    "        |\n",
    "       2*n\n",
    "       to \n",
    "     0 - - n\n",
    "     1 - - n+1\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "     n-1 -- 2*n-1   \n",
    "    '''\n",
    "    # Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\n",
    "    top_term = label[0]+label[n-1]+label[2*n-2] \n",
    "    top_tensor = tensor_list[0]\n",
    "    # Middle tensors (i = 2,..., n-1): shape (2,2,2,2)\n",
    "    for i in range(1, n - 2):\n",
    "        term = label[2*n-2] + label[i] + label[n + i - 1] + label[2*n - 1]\n",
    "        output_subscript = label[:i+1] + label[n-1:n+i] + label[2*n-1]\n",
    "        einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_term = label[:i+1] + label[n-1:n+i] + label[2*n-2]\n",
    "\n",
    "    # Rightmost tensor: shape (2,2,2)\n",
    "    term = label[n - 2] + label[2*n-2] + label[2*n - 3]\n",
    "    output_subscript = label[:2*n-2]\n",
    "    einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 2])\n",
    "\n",
    "    return top_tensor\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_column_ABC(n, plaq_dict, plaq, p, top_tensor):\n",
    "    \"\"\"\n",
    "    Contract the list of n bulk tensors with the top tensor from left to right.\n",
    "         _ 2n+1\n",
    "        |\n",
    "        2n\n",
    "       -n+1\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor_list = seq_ABC(n, plaq_dict, plaq, p)\n",
    "    top_terms = label[:2*n-2]\n",
    "    term = label[n-1]  + label[2*n-2] + label[2*n - 1]\n",
    "    output_subscript = label[:n-1]+ label[2*n-1] + label[2*n-2] + label[n:2*n-2] \n",
    "    einsum_subscript = top_terms + \",\" + term + \"->\" + output_subscript\n",
    "    \n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[0])\n",
    "    top_terms = label[:n] + label[2*n-2]+ label[n:2*n-2]\n",
    "\n",
    "    for i in range(1, n - 2):\n",
    "        term = label[n+i-1] + label[2*n-2] + label[2*n - 1] + label[2*n]\n",
    "        output_subscript = label[:n+i-1] + label[2*n - 1] + label[2*n - 2]  + label[n+i:2*n-2]\n",
    "        einsum_subscript = top_terms + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_terms = label[:n+i] + label[2*n-2] + label[n+i:2*n-2]\n",
    "    term = label[2*n - 3] + label[2*n-2] + label[2*n - 1]\n",
    "    output_subscript = label[:2*n-3] + label[2*n - 1]\n",
    "    einsum_subscript = top_terms + \",\" + term + \"->\" + output_subscript\n",
    "    final_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 2])\n",
    "\n",
    "    return final_tensor\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_ladder_ABC(n, plaq_dict, plaq, p, initial_tensor):\n",
    "    \"\"\"\n",
    "    Perform a ladder contraction over n tensors.\n",
    "        | (2n)\n",
    "      - (n+1)\n",
    "      - (n+2)\n",
    "        to\n",
    "        \n",
    "        - (2n+1\n",
    "        |(2n+2)\n",
    "       -(n+2)    \n",
    "    full tensor is labelled as \n",
    "       2\n",
    "    1    3 \n",
    "      4\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor = initial_tensor\n",
    "    \n",
    "    for i in range(n - 2):\n",
    "        term1 = label[:2*n-2]\n",
    "        term2 = label[n-1] + label[2*n-2]\n",
    "        output_subscript = label[:n-1]+label[2*n-2] + label[n:2*n-2]\n",
    "        einsum_subscript = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "        tensor = jnp.einsum(einsum_subscript, tensor, corner_tensor(plaq_dict[i][plaq[i][0]], p))\n",
    "        \n",
    "        for j in range(1, n - i - 1):\n",
    "            term2 = label[n + j - 1] + label[2*n-2] + label[2*n - 1] + label[2*n]\n",
    "            output_subscript = label[:n+j-2] + label[2*n - 1] + label [2*n] + label[n + j : 2*n-2]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][j]], p))\n",
    "            term1 = label[:n+j-1] + label[2*n-2] + label[n+j:2*n-2]\n",
    "    term1 = label[:2*n-2]\n",
    "    corner = corner_tensor(plaq_dict[n-2][plaq[n-2][0]], p)\n",
    "    term2 = label[n-1] + label[2*n-2]\n",
    "    output_subscript = label[:n-1] + label[n:2*n - 1]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "    tensor = jnp.einsum(einsum_str, tensor, corner)\n",
    "\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:04.051064Z",
     "start_time": "2025-04-18T23:16:04.022087Z"
    }
   },
   "id": "e40f14e99afb5ea1",
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:03.644747Z",
     "start_time": "2025-04-18T23:16:03.637750Z"
    }
   },
   "id": "9c4a9ca3f19ef13b",
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:04.099062Z",
     "start_time": "2025-04-18T23:16:04.085066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plaq_B_dict[0]"
   ],
   "id": "5c0eebfe9ab46535",
   "outputs": [
    {
     "data": {
      "text/plain": "{(1, 5): 0, (2, 5): 0}"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:04.192534Z",
     "start_time": "2025-04-18T23:16:04.178512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plaq_B[0]"
   ],
   "id": "c77b0e5e471790a8",
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 5), (2, 5)]"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": [
    "def initial_top_BC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Build a list of n tensors corresponding to the top row.\n",
    "    The leftmost and rightmost are boundary incomplete (shape (2,2)),\n",
    "    while the ones in between are boundary full (shape (2,2,2)).\n",
    "    \"\"\"\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(corner_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 4):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(incomplete_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-3]]\n",
    "    tensor_list.append(corner_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "def seq_BC(n, plaq_dict, plaq, p):\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 4):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-3]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_initial_BC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Contract a list of n top-boundary tensors from left to right.\n",
    "    The free vertical indices remain, and internal (horizontal) indices are contracted.\n",
    "    \"\"\"\n",
    "    # Define labels for the indices.\n",
    "    label = string.ascii_letters\n",
    "    # Initialize the tensor list.\n",
    "    tensor_list = initial_top_BC(n, plaq_dict, plaq, p)\n",
    "    #print(\"tensor_list:\", tensor_list)\n",
    "    # Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\n",
    "    top_term = label[0]+label[n - 2] \n",
    "    top_tensor = tensor_list[0]\n",
    "    # Middle tensors (i = 2,..., n-1): shape (2,2,2,2)\n",
    "    for i in range(1, n - 3):\n",
    "        term = label[n - 2] + label[i] + label[n - 1]\n",
    "        output_subscript = label[:i+1] + label[n - 1]\n",
    "        einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_term = label[:i+1] + label[n - 2]\n",
    "\n",
    "    # Rightmost tensor: shape (2,2,2)\n",
    "    term = label[n - 2] + label[n - 3] \n",
    "    output_subscript = label[:n-2]\n",
    "    einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 3])\n",
    "    #print(top_tensor)\n",
    "    return top_tensor\n",
    "\n",
    "def process_column_BC(n, plaq_dict, plaq, p, tensor):\n",
    "    \"\"\"\n",
    "    Process a column of tensors in the lattice.\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor_list = seq_BC(n, plaq_dict, plaq, p)\n",
    "    tensor1 = tensor\n",
    "    \n",
    "    term1 = label[:(n-2)]\n",
    "    term2 = label[0] + label[n-2] + label[n-1]\n",
    "    output_str = label[n-1]+label[n-2]+label[1:n-2] \n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[0])\n",
    "    term1 = label[0] + label[n-2] + label[1:n-2]\n",
    "    for j in range(1, n-3):\n",
    "        term2 = label[j] + label[(n-2)] + label[n-1] + label[n]\n",
    "        output_str = label[:j] + label[n-1] + label[n] + label[(j+1):(n-2)]\n",
    "        einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "        tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[j])\n",
    "        term1 = label[:j+1] + label[(n-2)] + label[(j+1):(n-2)]\n",
    "\n",
    "    term2 = label[n-3]+label[(n-2)] + label[(n-1)] \n",
    "    output_str = label[:(n-3)] + label[n-1]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[n-3])\n",
    "    return tensor1\n",
    "\n",
    "\n",
    "    \n",
    "def process_ladder_BC(n, plaq_dict, plaq, p, tensor):\n",
    "    label = string.ascii_letters\n",
    "    for i in range(n - 2):\n",
    "        term1 = label[:(n-2)]\n",
    "        term2 = label[0] + label[(n-2)]\n",
    "        output_subscript = label[n-2] + label[1:n-2]\n",
    "        einsum_subscript = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "        #print(einsum_subscript)\n",
    "        tensor = jnp.einsum(einsum_subscript, tensor, corner_tensor(plaq_dict[i][plaq[i][0]], p))\n",
    "        term1 = output_subscript\n",
    "        j = 0\n",
    "        for j in range(1, n - i - 2):\n",
    "\n",
    "            term2 = label[j] + label[(n-2)] + label[n-1] + label[n]\n",
    "            output_subscript = label[:j-1] + label[n-1] + label [n] + label[(j+1):(n-2)]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            #print(\"bulk:\", einsum_str)\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][j]], p))\n",
    "            term1 = label[:j] + label[(n-2)] + label[j+1:(n-2)]\n",
    "            \n",
    "        if i == 0:\n",
    "            term2 = label[n-2] + label[n-3]\n",
    "            output_subscript = label[:(n-2)]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            #print(\"end_first_col:\", einsum_str)\n",
    "            tensor = jnp.einsum(einsum_str, tensor, corner_tensor(plaq_dict[i][plaq[i][n-2]], p))\n",
    "            term1 = label[:(n-2)]\n",
    "        else:\n",
    "            term2 = label[j+1]+label[(n-2)]+label[n-1]+label[n]\n",
    "            output_subscript = label[:j] + label[n-1] + label [n] + label[j+2:n-2]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            #print(\"end_col:\", einsum_str)\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][n-i-2]], p))\n",
    "            term1 = label[:(n-2)]\n",
    "\n",
    "    term2 = label[0] + label[(n-2)]\n",
    "    output_subscript = label[n-2]+label[1:(n-2)]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "    #print(einsum_str)\n",
    "    tensor = jnp.einsum(einsum_str, tensor, corner_tensor(plaq_dict[n-2][plaq[n-2][0]], p))\n",
    "\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:04.502384Z",
     "start_time": "2025-04-18T23:16:04.472461Z"
    }
   },
   "id": "86d2609092603ed2",
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "source": [
    "def initial_top_AC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Build a list of n tensors corresponding to the top row.\n",
    "    The leftmost and rightmost are boundary incomplete (shape (2,2)),\n",
    "    while the ones in between are boundary full (shape (2,2,2)).\n",
    "    \"\"\"\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(inner_corner_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(inner_edge_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_corner_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "def seq_AC(n, plaq_dict, plaq, p):\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_edge_tensor(m, p))  # right boundary, shape (2,2,2)\n",
    "    return tensor_list\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_initial_AC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Contract a list of n top-boundary tensors from left to right.\n",
    "    The free vertical indices remain, and internal (horizontal) indices are contracted.\n",
    "    \"\"\"\n",
    "    # Define labels for the indices.\n",
    "    label = string.ascii_letters\n",
    "    # Initialize the tensor list.\n",
    "    tensor_list = initial_top_AC(n, plaq_dict, plaq, p)\n",
    "\n",
    "    # Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\n",
    "    top_term = label[0]+label[n - 1] \n",
    "    top_tensor = tensor_list[0]\n",
    "    # Middle tensors (i = 2,..., n-1): shape (2,2,2,2)\n",
    "    for i in range(1, n - 2):\n",
    "        term = label[n - 1] + label[i] + label[n]\n",
    "        output_subscript = label[:i+1] + label[n]\n",
    "        einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_term = label[:i+1] + label[n - 1]\n",
    "\n",
    "    # Rightmost tensor: shape (2,2,2)\n",
    "    term = label[n - 1] + label[n - 2] \n",
    "    output_subscript = label[:n-1]\n",
    "    einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 2])\n",
    "\n",
    "    return top_tensor\n",
    "\n",
    "def process_column_AC(n, plaq_dict, plaq, p, tensor):\n",
    "    \"\"\"\n",
    "    Process a column of tensors in the lattice.\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor_list = seq_AC(n, plaq_dict, plaq, p)\n",
    "    tensor1 = tensor\n",
    "    \n",
    "    term1 = label[:(n-1)]\n",
    "    term2 = label[0] + label[n-1] + label[n]\n",
    "    output_str = label[n]+label[n-1]+label[1:n-1] \n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[0])\n",
    "    term1 = label[0] + label[n-1] + label[1:n-1]\n",
    "\n",
    "    for j in range(1, n-2):\n",
    "        term2 = label[j] + label[(n-1)] + label[n] + label[n+1]\n",
    "        output_str = label[:j] + label[n] + label[n+1] + label[(j+1):(n-1)]\n",
    "        einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "        tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[j])\n",
    "        term1 = label[:j+1] + label[(n-1)] + label[(j+1):(n-1)]\n",
    "    term2 = label[n-2]+label[(n-1)] + label[n] \n",
    "    output_str = label[:(n-2)] + label[n]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[n-2])\n",
    "    return tensor1\n",
    "    \n",
    "def process_ladder_AC(n, plaq_dict, plaq, p, tensor):\n",
    "    # Only here the plaq_dict is a list of dict.\n",
    "    label = string.ascii_letters\n",
    "    for i in range(n - 2):\n",
    "        term1 = label[:(n-1)]\n",
    "        term2 = label[0] + label[(n-1)]\n",
    "        output_subscript = label[n-1] + label[1:n-1]\n",
    "        einsum_subscript = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "        tensor = jnp.einsum(einsum_subscript, tensor, corner_tensor(plaq_dict[i][plaq[i][0]], p))\n",
    "        term1 = output_subscript\n",
    "        for j in range(1, n - i - 1):\n",
    "            term2 = label[j] + label[n-1] + label[n] + label[n+1]\n",
    "            output_subscript = label[:j-1] + label[n+1] + label [n] + label[(j+1):(n-1)]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][j]], p))\n",
    "            term1 = label[:j] + label[(n-1)] + label[j+1:(n-1)]\n",
    "    term1 = label[:(n-1)]\n",
    "    term2 = label[0] + label[n-1]\n",
    "    output_subscript = label[n-1]+label[1:(n-1)]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "    tensor = jnp.einsum(einsum_str, tensor, corner_tensor(plaq_dict[n-2][plaq[n-2][0]], p))\n",
    "\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:04.905880Z",
     "start_time": "2025-04-18T23:16:04.737494Z"
    }
   },
   "id": "665e521c2f89e0ac",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T23:16:04.998883Z",
     "start_time": "2025-04-18T23:16:04.993017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def n_tensor_product_shape_2(n, p):\n",
    "    vec = jnp.sqrt(jnp.array([1 - p, p]))\n",
    "    result = vec\n",
    "    for _ in range(n - 1):\n",
    "        result = jnp.tensordot(result, vec, axes=0)\n",
    "    return result"
   ],
   "id": "f5f599b5e6a63a13",
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "source": [
    "def Pr_m_B_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor = process_initial_BC(n, plaq_dict[0], plaq[0], p)\n",
    "    for i in range(1, n-2):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
    "    Pr_m_B = jnp.sum(ini_tensor)\n",
    "    return Pr_m_B\n",
    "\n",
    "def Pr_m_C_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor1 = process_initial_BC(n, plaq_dict[0], plaq[0], p)\n",
    "    for i in range(1, n):\n",
    "        ini_tensor1 = process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor1)\n",
    "    ini_tensor1 = process_ladder_BC(n, plaq_dict[n:2*n-1], plaq[n:2*n-1], p, ini_tensor1)\n",
    "\n",
    "    ini_tensor2 = process_initial_BC(n, plaq_dict[2*n-1], plaq[2*n-1], p)\n",
    "    for i in range(n-1):\n",
    "        ini_tensor2 = process_column_BC(n, plaq_dict[2*n+i], plaq[2*n+i], p, ini_tensor2)\n",
    "    ini_tensor2 = process_ladder_BC(n, plaq_dict[3*n-1:4*n-2], plaq[3*n-1:4*n-2], p, ini_tensor2)\n",
    "    revision_vec = n_tensor_product_shape_2(n-2, p)\n",
    "    Pr_m_C = jnp.sum(ini_tensor1*revision_vec)*jnp.sum(ini_tensor2*revision_vec)\n",
    "    return Pr_m_C\n",
    "\n",
    "def Pr_m_BC_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor = process_initial_BC(n, plaq_dict[0], plaq[0], p)\n",
    "    #print(\"ini:\", ini_tensor)\n",
    "    for i in range(1, n):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
    "        #print(\"col:\", ini_tensor)\n",
    "    ini_tensor = process_ladder_BC(n, plaq_dict[n:2*n-1], plaq[n:2*n-1], p, ini_tensor)\n",
    "    #print(\"ladder:\", ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[2*n-1+i], plaq[2*n-1+i], p, ini_tensor)\n",
    "        #print(\"col:\", ini_tensor)\n",
    "    ini_tensor = process_ladder_BC(n, plaq_dict[3*n-1:4*n-2], plaq[3*n-1:4*n-2], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[4*n-2+i], plaq[4*n-2+i], p, ini_tensor)\n",
    "    \n",
    "    revision_vec = n_tensor_product_shape_2(n-2, p)\n",
    "    Pr_m_BC = jnp.sum(ini_tensor*revision_vec)\n",
    "    \n",
    "    return Pr_m_BC\n",
    "\n",
    "def Pr_m_AC_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor = process_initial_AC(n, plaq_dict[0], plaq[0], p)\n",
    "    #print(\"ini_before_ladder:\", ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[1:n], plaq[1:n], p, ini_tensor)\n",
    "    #print(\"ini_after_ladder:\", ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_AC(n, plaq_dict[n+i], plaq[n+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[2*n:3*n-1], plaq[2*n:3*n-1], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_AC(n, plaq_dict[3*n-1+i], plaq[3*n-1+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[4*n-1:5*n-2], plaq[4*n-1:5*n-2], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_AC(n, plaq_dict[5*n-2+i], plaq[5*n-2+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[6*n-2:7*n-3], plaq[6*n-2:7*n-3], p, ini_tensor)\n",
    "    Pr_m_AC = jnp.sum(ini_tensor, axis = -1)\n",
    "    revision_vec = n_tensor_product_shape_2(n-2, p)\n",
    "    Pr_m_AC = jnp.sum(ini_tensor*revision_vec)\n",
    "    return Pr_m_AC\n",
    "\n",
    "def Pr_m_ABC_func(n, plaq_dict, plaq, p):\n",
    "    label = string.ascii_letters\n",
    "    ini_tensor = process_initial_ABC(n, plaq_dict[0], plaq[0], p)\n",
    "    for i in range(1, n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[n:2*n-1], plaq[n:2*n-1], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[2*n-1+i], plaq[2*n-1+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[3*n-1:4*n-2], plaq[3*n-1:4*n-2], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[4*n-2+i], plaq[4*n-2+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[5*n-2:6*n-3], plaq[5*n-2:6*n-3], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[6*n-3+i], plaq[6*n-3+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[7*n-3:8*n-4], plaq[7*n-3:8*n-4], p, ini_tensor)\n",
    "    einsum_str = label[:n-1]+label[:n-1] + \"->\" \n",
    "    return jnp.einsum(einsum_str, ini_tensor)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:51:24.965521Z",
     "start_time": "2025-04-18T23:51:24.937149Z"
    }
   },
   "id": "916e55a54ab69dcc",
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "source": [
    "plaq_BC_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:51:25.278145Z",
     "start_time": "2025-04-18T23:51:25.268146Z"
    }
   },
   "id": "24819dbc9d728256",
   "outputs": [
    {
     "data": {
      "text/plain": "[{(7, 1): 0, (7, 2): 0},\n {(6, 1): 1, (6, 2): 0},\n {(5, 1): 0, (5, 2): 0},\n {(4, 1): 1, (4, 2): 0},\n {(3, 1): 0, (3, 2): 0, (3, 3): 0},\n {(2, 2): 1, (2, 3): 0},\n {(1, 3): 0},\n {(1, 4): 0, (2, 4): 1},\n {(1, 5): 1, (2, 5): 0},\n {(1, 6): 0, (2, 6): 0},\n {(1, 7): 0, (2, 7): 0},\n {(1, 8): 0, (2, 8): 0, (3, 8): 1},\n {(2, 9): 0, (3, 9): 0},\n {(3, 10): 1},\n {(4, 10): 1, (4, 9): 0},\n {(5, 10): 0, (5, 9): 0},\n {(6, 10): 0, (6, 9): 0},\n {(7, 10): 0, (7, 9): 0}]"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "def metropolis_step(n, plaq_dict, Pr_func, plaq, p, num_samples, kind):\n",
    "    \"\"\"\n",
    "    Perform num_samples Metropolis updates on plaq_dict.\n",
    "    \n",
    "    Args:\n",
    "      n             : system size\n",
    "      plaq_dict     : current configuration (dict-of-dicts)\n",
    "      Pr_func       : function signature Pr = Pr_func(n, config, plaq, p)\n",
    "      plaq          : any auxiliary data needed by Pr_func\n",
    "      p             : model parameter\n",
    "      num_samples   : how many proposed flips to attempt\n",
    "\n",
    "    Returns:\n",
    "      plaq_dict_new : updated configuration after all steps\n",
    "      w_list        : list of log‑probabilities at each step (length num_samples+1)\n",
    "    \"\"\"\n",
    "    w_list = []\n",
    "    Pr0 = Pr_func(n, plaq_dict, plaq, p)\n",
    "    w_list.append(jnp.log(Pr0))\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        if kind in (\"C\", \"BC\"):\n",
    "            candidate = flip_one_free(plaq_dict)\n",
    "        else:\n",
    "            candidate = flip_one(plaq_dict, n, kind)\n",
    "        Pr  = Pr_func(n, candidate, plaq, p)\n",
    "        # accept with Metropolis criterion\n",
    "        if random.random() < (Pr / Pr0):\n",
    "            #print(\"accept\")\n",
    "            plaq_dict = candidate\n",
    "            Pr0       = Pr\n",
    "        w_list.append(jnp.log(Pr0))\n",
    "\n",
    "    return plaq_dict, w_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T23:51:25.602410Z",
     "start_time": "2025-04-18T23:51:25.584170Z"
    }
   },
   "id": "af0f37ea7f6040a3",
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "source": [
    "p = 0.5\n",
    "num_samples = 30\n",
    "keyC, keyBC, keyAC, keyABC = jax.random.PRNGKey(0), jax.random.PRNGKey(1), jax.random.PRNGKey(2), jax.random.PRNGKey(3)\n",
    "w_c, w_bc, w_ac, w_abc = [], [], [], []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T02:01:18.512853Z",
     "start_time": "2025-04-19T02:01:18.493641Z"
    }
   },
   "id": "cc983b5989fec1ca",
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n",
      "tensor_list: [Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64), Array([[0.25, 0.25],\n",
      "       [0.25, 0.25]], dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plaq_C_dict,  w_c = metropolis_step(n, plaq_C_dict, Pr_m_C_func, plaq_C, p, num_samples, \"C\")\n",
    "plaq_BC_dict, w_bc = metropolis_step(n, plaq_BC_dict, Pr_m_BC_func, plaq_BC, p, num_samples, \"BC\")\n",
    "plaq_AC_dict, w_ac = metropolis_step(n, plaq_AC_dict, Pr_m_AC_func, plaq_AC, p, num_samples, \"AC\")\n",
    "plaq_ABC_dict, w_abc = metropolis_step(n, plaq_ABC_dict, Pr_m_ABC_func, plaq_ABC, p, num_samples, \"ABC\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T02:02:28.991091Z",
     "start_time": "2025-04-19T02:01:18.745995Z"
    }
   },
   "id": "40a6bfb9f51dea32",
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T23:54:00.788433Z",
     "start_time": "2025-04-18T23:54:00.758994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "incomplete_tensor(0, 0.5)"
   ],
   "id": "2f492fbc794c52e",
   "outputs": [
    {
     "data": {
      "text/plain": "Array([[[0.1767767, 0.1767767],\n        [0.1767767, 0.1767767]],\n\n       [[0.1767767, 0.1767767],\n        [0.1767767, 0.1767767]]], dtype=float64)"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": [
    "-jnp.sum(jnp.array(w_ac) + jnp.array(w_bc) - jnp.array(w_abc) - jnp.array(w_c))/num_samples/jnp.log(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T02:10:26.093390Z",
     "start_time": "2025-04-19T02:10:25.938783Z"
    }
   },
   "id": "d4c0ce426c6edde9",
   "outputs": [
    {
     "data": {
      "text/plain": "Array(8.78333333, dtype=float64)"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "source": [
    "jnp.sum(jnp.array(w_ac) + jnp.array(w_bc) - jnp.array(w_abc) - jnp.array(w_b))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T06:11:02.846898Z",
     "start_time": "2025-04-18T06:11:02.827804Z"
    }
   },
   "id": "8270fa3a206ed7dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4c934bc70a100d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plaq_dict_m [{(1, 6): 0, (2, 6): 0, (3, 6): 0}, {(1, 7): 0, (2, 7): 0, (3, 7): 0}, {(1, 8): 0, (2, 8): 0, (3, 8): 0}]\n"
     ]
    },
    {
     "ename": "TracerBoolConversionError",
     "evalue": "Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function step at C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_32880\\2635678145.py:23 for scan. This concrete value was not available in Python because it depends on the value of the argument carry[0][0][(1, 6)].\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTracerBoolConversionError\u001B[0m                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[107], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m AC_sampler \u001B[38;5;241m=\u001B[39m make_metropolis(Pr_m_AC_func, plaq_AC, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAC\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m ABC_sampler \u001B[38;5;241m=\u001B[39m make_metropolis(Pr_m_ABC_func, plaq_ABC, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mABC\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 11\u001B[0m plaq_B_dict,  w_b  \u001B[38;5;241m=\u001B[39m \u001B[43mB_sampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq_B_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeyB\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m plaq_BC_dict, w_bc \u001B[38;5;241m=\u001B[39m BC_sampler(n, plaq_BC_dict, p, num_samples, keyBC)\n\u001B[0;32m     13\u001B[0m plaq_AC_dict, w_ac \u001B[38;5;241m=\u001B[39m AC_sampler(n, plaq_AC_dict, p, num_samples, keyAC)\n",
      "Cell \u001B[1;32mIn[106], line 39\u001B[0m, in \u001B[0;36mmake_metropolis.<locals>.metropolis_step\u001B[1;34m(n, plaq_dict, p, num_samples, keym)\u001B[0m\n\u001B[0;32m     36\u001B[0m     w \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mlog(new_Pr)\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (new_config, new_Pr), w\n\u001B[1;32m---> 39\u001B[0m (final_config, _), w_scan \u001B[38;5;241m=\u001B[39m \u001B[43mlax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mplaq_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPr0\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeym\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m final_config, jnp\u001B[38;5;241m.\u001B[39mconcatenate((jnp\u001B[38;5;241m.\u001B[39marray([w0]), w_scan))\n",
      "    \u001B[1;31m[... skipping hidden 9 frame]\u001B[0m\n",
      "Cell \u001B[1;32mIn[106], line 30\u001B[0m, in \u001B[0;36mmake_metropolis.<locals>.metropolis_step.<locals>.step\u001B[1;34m(carry, r_key)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     29\u001B[0m     candidate \u001B[38;5;241m=\u001B[39m flip_one(config, n, kind)\n\u001B[1;32m---> 30\u001B[0m Pr_cand \u001B[38;5;241m=\u001B[39m \u001B[43mPr_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcandidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# accept with Metropolis criterion\u001B[39;00m\n\u001B[0;32m     32\u001B[0m accept \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(k2) \u001B[38;5;241m<\u001B[39m (Pr_cand \u001B[38;5;241m/\u001B[39m Pr_prev)\n",
      "Cell \u001B[1;32mIn[104], line 2\u001B[0m, in \u001B[0;36mPr_m_B_func\u001B[1;34m(n, plaq_dict, plaq, p)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mPr_m_B_func\u001B[39m(n, plaq_dict, plaq, p):\n\u001B[1;32m----> 2\u001B[0m     ini_tensor \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_initial_BC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m      4\u001B[0m         ini_tensor \u001B[38;5;241m=\u001B[39m process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
      "Cell \u001B[1;32mIn[98], line 39\u001B[0m, in \u001B[0;36mprocess_initial_BC\u001B[1;34m(n, plaq_dict, plaq, p)\u001B[0m\n\u001B[0;32m     37\u001B[0m label \u001B[38;5;241m=\u001B[39m string\u001B[38;5;241m.\u001B[39mascii_letters\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Initialize the tensor list.\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m tensor_list \u001B[38;5;241m=\u001B[39m \u001B[43minitial_top_BC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\u001B[39;00m\n\u001B[0;32m     42\u001B[0m top_term \u001B[38;5;241m=\u001B[39m label[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m+\u001B[39mlabel[n \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m] \n",
      "Cell \u001B[1;32mIn[98], line 10\u001B[0m, in \u001B[0;36minitial_top_BC\u001B[1;34m(n, plaq_dict, plaq, p)\u001B[0m\n\u001B[0;32m      7\u001B[0m tensor_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      9\u001B[0m m \u001B[38;5;241m=\u001B[39m plaq_dict[plaq[\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m---> 10\u001B[0m tensor_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43mcorner_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m)  \u001B[38;5;66;03m# left boundary, shape (2,2)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m4\u001B[39m):\n\u001B[0;32m     12\u001B[0m     m \u001B[38;5;241m=\u001B[39m plaq_dict[plaq[i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m]]\n",
      "File \u001B[1;32m~\\PycharmProjects\\UIUC_test\\util.py:416\u001B[0m, in \u001B[0;36mcorner_tensor\u001B[1;34m(m, p)\u001B[0m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcorner_tensor\u001B[39m(m, p):\n\u001B[0;32m    415\u001B[0m     tensor_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 416\u001B[0m     Q \u001B[38;5;241m=\u001B[39m \u001B[43mQ_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    417\u001B[0m     T \u001B[38;5;241m=\u001B[39m T_tensor(p)\n\u001B[0;32m    418\u001B[0m     bT \u001B[38;5;241m=\u001B[39m boundary_T_tensor(p)\n",
      "File \u001B[1;32m~\\PycharmProjects\\UIUC_test\\util.py:370\u001B[0m, in \u001B[0;36mQ_tensor\u001B[1;34m(m)\u001B[0m\n\u001B[0;32m    368\u001B[0m                 parity \u001B[38;5;241m=\u001B[39m (s1 \u001B[38;5;241m+\u001B[39m s2 \u001B[38;5;241m+\u001B[39m s3 \u001B[38;5;241m+\u001B[39m s4) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    369\u001B[0m                 \u001B[38;5;66;03m# If parity matches the anyon measurement, set entry to 1.\u001B[39;00m\n\u001B[1;32m--> 370\u001B[0m                 value \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mparity\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    371\u001B[0m                 Q \u001B[38;5;241m=\u001B[39m Q\u001B[38;5;241m.\u001B[39mat[s1, s2, s3, s4]\u001B[38;5;241m.\u001B[39mset(value)\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Q\n",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\UIUC_test\\.venv\\lib\\site-packages\\jax\\_src\\core.py:1517\u001B[0m, in \u001B[0;36mconcretization_function_error.<locals>.error\u001B[1;34m(self, arg)\u001B[0m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21merror\u001B[39m(\u001B[38;5;28mself\u001B[39m, arg):\n\u001B[1;32m-> 1517\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m TracerBoolConversionError(arg)\n",
      "\u001B[1;31mTracerBoolConversionError\u001B[0m: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function step at C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_32880\\2635678145.py:23 for scan. This concrete value was not available in Python because it depends on the value of the argument carry[0][0][(1, 6)].\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
     ]
    }
   ],
   "source": [
    "p = 0.1\n",
    "num_samples = 3\n",
    "keyB, keyBC, keyAC, keyABC = jax.random.PRNGKey(0), jax.random.PRNGKey(1), jax.random.PRNGKey(2), jax.random.PRNGKey(3)\n",
    "w_b, w_bc, w_ac, w_abc = [], [], [], []\n",
    "\n",
    "B_sampler = make_metropolis(Pr_m_B_func, plaq_B, \"B\")\n",
    "BC_sampler = make_metropolis(Pr_m_BC_func, plaq_BC, \"BC\")\n",
    "AC_sampler = make_metropolis(Pr_m_AC_func, plaq_AC, \"AC\")\n",
    "ABC_sampler = make_metropolis(Pr_m_ABC_func, plaq_ABC, \"ABC\")\n",
    "\n",
    "plaq_B_dict,  w_b  = B_sampler(n, plaq_B_dict, p, num_samples, keyB)\n",
    "plaq_BC_dict, w_bc = BC_sampler(n, plaq_BC_dict, p, num_samples, keyBC)\n",
    "plaq_AC_dict, w_ac = AC_sampler(n, plaq_AC_dict, p, num_samples, keyAC)\n",
    "plaq_ABC_dict, w_abc = ABC_sampler(n, plaq_ABC_dict, p, num_samples, keyABC)\n",
    "\n",
    "CMI = jnp.sum(jnp.array(w_ac) + jnp.array(w_bc) - jnp.array(w_abc) - jnp.array(w_b))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T22:18:57.290800Z",
     "start_time": "2025-04-17T22:18:57.053256Z"
    }
   },
   "id": "8ec102584edf806a",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Array([[[[0., 1.],\n         [1., 0.]],\n\n        [[1., 0.],\n         [0., 1.]]],\n\n\n       [[[1., 0.],\n         [0., 1.]],\n\n        [[0., 1.],\n         [1., 0.]]]], dtype=float64)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_tensor(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T22:27:20.276883Z",
     "start_time": "2025-04-17T22:27:20.258014Z"
    }
   },
   "id": "9ad4ba43ef5d894d",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[[(1, 6), (2, 6), (3, 6)], [(1, 7), (2, 7), (3, 7)], [(1, 8), (2, 8), (3, 8)]]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaq_B"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T22:12:29.747004Z",
     "start_time": "2025-04-17T22:12:29.733050Z"
    }
   },
   "id": "433fe3e60c23e1a7",
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = 0\n",
    "'''\n",
    "def make_metropolis(Pr_func, plaq, kind):\n",
    "    #@partial(jax.jit, static_argnums=(0, ))\n",
    "    def metropolis_step(n, plaq_dict, p, num_samples, keym):\n",
    "        \"\"\"\n",
    "        Perform `num_samples` Metropolis updates on `plaq_dict`.\n",
    "\n",
    "        Args:\n",
    "          n             : system size\n",
    "          plaq_dict     : current configuration (dict-of-dicts)\n",
    "          Pr_func       : function signature Pr = Pr_func(n, config, plaq, p)\n",
    "          plaq          : any auxiliary data needed by Pr_func\n",
    "          p             : model parameter\n",
    "          num_samples   : how many proposed flips to attempt\n",
    "\n",
    "        Returns:\n",
    "          plaq_dict_new : updated configuration after all steps\n",
    "          w_list        : list of log‑probabilities at each step (length num_samples+1)\n",
    "        \"\"\"\n",
    "        print(\"plaq_dict_m\", plaq_dict)\n",
    "        Pr0 = Pr_func(n, plaq_dict, plaq, p)\n",
    "        w0 = jnp.log(Pr0)\n",
    "\n",
    "        def step(carry, r_key):\n",
    "            config, Pr_prev = carry\n",
    "            k1, k2 = jax.random.split(r_key)\n",
    "            if kind in (\"B\", \"BC\"):\n",
    "                candidate = flip_one_free(config)\n",
    "            else:\n",
    "                candidate = flip_one(config, n, kind)\n",
    "            Pr_cand = Pr_func(n, candidate, plaq, p)\n",
    "            # accept with Metropolis criterion\n",
    "            accept = jax.random.uniform(k2) < (Pr_cand / Pr_prev)\n",
    "            new_config = lax.select(accept, candidate, config)\n",
    "            new_Pr = lax.select(accept, Pr_cand, Pr_prev)\n",
    "\n",
    "            w = jnp.log(new_Pr)\n",
    "            return (new_config, new_Pr), w\n",
    "\n",
    "        (final_config, _), w_scan = lax.scan(step, (plaq_dict, Pr0), jax.random.split(keym, num_samples))\n",
    "\n",
    "        return final_config, jnp.concatenate((jnp.array([w0]), w_scan))\n",
    "    return metropolis_step\n",
    "'''\n",
    "b = 0"
   ],
   "id": "c4af85b09e9d0a6c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "def H_B_tensor(n, plaq, p):\n",
    "    label = string.ascii_letters\n",
    "    tensor1 = incomplete_tensor(plaq_dict[plaq[0, 0]], p)\n",
    "    term1 = label[0] + label[n - 2] + label[2*(n-2)]\n",
    "    for i in range(n-4):\n",
    "        tensor2 = full_tensor(plaq_dict[plaq[0, i+1]], p)\n",
    "        term2 = label[i+1] + label[2*(n-2)]  + label[n - 2 + i + 1] + label[2*(n-2) + 1]\n",
    "        output_str = label[:i+1] + label[n-2:n+i+2] + label[2*(n-2)+1]\n",
    "        einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "        tensor1 = jnp.einsum(einsum_str, tensor1, tensor2)\n",
    "        term1 = label[:i+1] + label[n-2:n+i+2] + label[2*(n-2)]\n",
    "    tensor2 = incomplete_tensor(plaq_dict[plaq[0, n-3]])\n",
    "    term2 = label[n-3] + label[2*(n-2)] + label[2*(n-2) - 1]\n",
    "    output_str = label[:2*(n-2)]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor2)\n",
    "    for i in range(1, n):\n",
    "        tensor1 = process_column(n, plaq[i], p, tensor1)\n",
    "    return tensor1\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ebdc9fa615a3de9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "all_plaq = list(chain(\n",
    "    ((r, c) for r in range(1, n-1) for c in range(n, 2*n)), # top middle\n",
    "    ((2*n + r, c) for r in range(1, n-1) for c in range(n, 2*n)),  # bottom middle\n",
    "    ((r, c) for r in range(n, 2*n) for c in range(1, n-1)),\n",
    "    ((r, 2*n+c) for r in range(n, 2*n) for c in range(1, n-1)),\n",
    "    ((r, n-r+c) for r in range(n) for c in range(r)),\n",
    "    ((r, 2*n+c) for r in range(n) for c in range(r)),\n",
    "    ((2*n+r, c) for c in range(n) for r in range(c)),  \n",
    "    ((2*n+r, 2*n+c) for c in range(n) for r in range(n-c-1)),\n",
    "    ((n-1, n+c) for c in range(n)),\n",
    "    ((2*n, n+c) for c in range(n)),\n",
    "    ((n+r, n-1) for r in range(n)),\n",
    "    ((n+r, 2*n) for r in range(n)),\n",
    "))\n",
    "plaq_dict = {key: 0. for key in all_plaq}\n",
    "\n",
    "print(\"all_plaq:\", all_plaq)\n",
    "def region_plaquettes(regionEdges, all_plaq):\n",
    "    \"\"\"\n",
    "    For a given set of allowed edges (regionE\n",
    "    dges), return the list of plaquettes\n",
    "    (by their top-left coordinate) that are partially contained in the region.\n",
    "    \"\"\"\n",
    "    plaq = []\n",
    "    for (r, c) in all_plaq:\n",
    "        edges = [((r, c), 'H'),\n",
    "                 ((r+1, c), 'H'),\n",
    "                 ((r, c), 'V'),\n",
    "                 ((r, c+1), 'V')]\n",
    "        if all(e in regionEdges for e in edges):\n",
    "            plaq.append((r, c))\n",
    "    return plaq\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ee5dcac202c32e2",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
