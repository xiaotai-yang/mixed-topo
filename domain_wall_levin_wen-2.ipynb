{
 "cells": [
  {
   "cell_type": "code",
   "id": "63dad47a3ef7b959",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.645269Z",
     "start_time": "2025-04-19T03:12:40.505463Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from itertools import chain\n",
    "import string\n",
    "from functools import partial\n",
    "from jax import config, lax\n",
    "from util import *\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "n = 4\n",
    "setA, setB, setC = plot_regions(n)\n",
    "plaq_ABC, plaq_C, plaq_BC, plaq_AC = plaq_ABC_func(n), plaq_C_func(n), plaq_BC_func(n), plaq_AC_func(n)\n",
    "plaq_B = plaq_B_func(n)\n",
    "\n",
    "plaq_ABC_dict = [ dict.fromkeys(row, 0) for row in plaq_ABC ]\n",
    "plaq_B_dict = [ dict.fromkeys(row, 0) for row in plaq_B ]\n",
    "plaq_C_dict = [dict.fromkeys(row, 0) for row in plaq_C ]\n",
    "plaq_BC_dict = [ dict.fromkeys(row, 0) for row in plaq_BC ]\n",
    "plaq_AC_dict = [ dict.fromkeys(row, 0) for row in plaq_AC ]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 700x700 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setA: {((9, 8), 'V'), ((10, 9), 'H'), ((10, 4), 'H'), ((8, 6), 'V'), ((9, 3), 'V'), ((9, 6), 'H'), ((9, 5), 'H'), ((11, 7), 'H'), ((10, 5), 'H'), ((8, 8), 'V'), ((11, 6), 'H'), ((9, 7), 'H'), ((10, 8), 'V'), ((9, 1), 'H'), ((8, 11), 'V'), ((11, 8), 'H'), ((8, 1), 'V'), ((9, 8), 'H'), ((9, 4), 'V'), ((9, 3), 'H'), ((11, 3), 'H'), ((10, 6), 'V'), ((10, 3), 'V'), ((9, 2), 'V'), ((9, 9), 'V'), ((10, 8), 'H'), ((8, 7), 'V'), ((9, 10), 'V'), ((9, 4), 'H'), ((11, 5), 'V'), ((10, 7), 'H'), ((10, 7), 'V'), ((8, 9), 'V'), ((11, 4), 'V'), ((10, 6), 'H'), ((10, 9), 'V'), ((9, 2), 'H'), ((10, 3), 'H'), ((8, 3), 'V'), ((8, 2), 'V'), ((9, 6), 'V'), ((10, 4), 'V'), ((9, 9), 'H'), ((9, 5), 'V'), ((10, 2), 'H'), ((8, 5), 'V'), ((11, 7), 'V'), ((8, 4), 'V'), ((11, 6), 'V'), ((11, 5), 'H'), ((8, 10), 'V'), ((9, 7), 'V'), ((9, 10), 'H'), ((11, 8), 'V'), ((11, 4), 'H'), ((10, 5), 'V')}\n",
      "setB: {((1, 7), 'H'), ((2, 6), 'V'), ((3, 6), 'V'), ((3, 5), 'V'), ((1, 6), 'V'), ((3, 4), 'H'), ((0, 6), 'V'), ((3, 7), 'V'), ((2, 5), 'V'), ((2, 6), 'H'), ((3, 6), 'H'), ((0, 5), 'V'), ((3, 5), 'H'), ((1, 6), 'H'), ((2, 7), 'V'), ((3, 7), 'H'), ((1, 5), 'V'), ((2, 5), 'H'), ((2, 4), 'H'), ((0, 7), 'V'), ((1, 4), 'H'), ((1, 7), 'V'), ((2, 7), 'H'), ((1, 5), 'H')}\n",
      "setC: {((8, 3), 'H'), ((1, 3), 'V'), ((7, 3), 'H'), ((5, 1), 'V'), ((7, 10), 'V'), ((3, 10), 'H'), ((7, 9), 'V'), ((7, 11), 'V'), ((5, 0), 'H'), ((2, 4), 'V'), ((7, 10), 'H'), ((5, 3), 'V'), ((4, 8), 'H'), ((5, 2), 'H'), ((4, 3), 'H'), ((4, 10), 'H'), ((5, 3), 'H'), ((2, 3), 'V'), ((6, 10), 'H'), ((6, 0), 'H'), ((2, 2), 'H'), ((4, 1), 'V'), ((5, 11), 'V'), ((4, 9), 'H'), ((1, 8), 'V'), ((7, 8), 'H'), ((6, 1), 'V'), ((8, 2), 'H'), ((6, 11), 'H'), ((3, 1), 'V'), ((6, 2), 'V'), ((6, 1), 'H'), ((1, 3), 'H'), ((3, 3), 'V'), ((4, 11), 'V'), ((8, 8), 'H'), ((5, 1), 'H'), ((1, 9), 'V'), ((7, 1), 'V'), ((3, 1), 'H'), ((7, 9), 'H'), ((8, 11), 'H'), ((3, 3), 'H'), ((7, 11), 'H'), ((4, 11), 'H'), ((2, 8), 'V'), ((5, 9), 'V'), ((3, 2), 'V'), ((2, 10), 'V'), ((3, 4), 'V'), ((3, 11), 'V'), ((0, 4), 'V'), ((8, 9), 'H'), ((2, 8), 'H'), ((5, 10), 'V'), ((7, 2), 'V'), ((3, 2), 'H'), ((2, 3), 'H'), ((4, 2), 'V'), ((6, 8), 'H'), ((3, 8), 'V'), ((8, 10), 'H'), ((2, 9), 'V'), ((4, 1), 'H'), ((5, 11), 'H'), ((1, 8), 'H'), ((4, 2), 'H'), ((6, 9), 'V'), ((6, 3), 'V'), ((5, 8), 'H'), ((6, 2), 'H'), ((6, 9), 'H'), ((0, 8), 'V'), ((3, 9), 'V'), ((7, 3), 'V'), ((7, 1), 'H'), ((7, 0), 'H'), ((3, 10), 'V'), ((5, 9), 'H'), ((4, 0), 'H'), ((5, 2), 'V'), ((4, 3), 'V'), ((4, 10), 'V'), ((5, 10), 'H'), ((8, 0), 'H'), ((7, 2), 'H'), ((1, 4), 'V'), ((3, 8), 'H'), ((6, 10), 'V'), ((2, 9), 'H'), ((8, 1), 'H'), ((2, 2), 'V'), ((4, 9), 'V'), ((6, 3), 'H'), ((3, 9), 'H'), ((6, 11), 'V')}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "def flip_one_free(plaq_zero):\n",
    "    # if plaq_zero is a dict-of-dicts:\n",
    "    plaq = copy.deepcopy(plaq_zero)\n",
    "    i = random.choice([i for i in range (len(plaq_zero))])\n",
    "    # if it’s a list-of-dicts, you’d do:\n",
    "    # i = random.randrange(len(plaq_zero))\n",
    "    \n",
    "    inner_keys = list(plaq_zero[i].keys())\n",
    "    k = random.choice(inner_keys)\n",
    "    \n",
    "    # flip 0↔1\n",
    "    plaq[i][k] = 1 - plaq_zero[i][k]\n",
    "    \n",
    "    return plaq\n",
    "\n",
    "def is_on_hole_boundary(coord, n, kind=\"ABC\"):\n",
    "    \"\"\"\n",
    "    coord:  (r, c)\n",
    "    n:      lattice parameter\n",
    "    kind:   either \"ABC\" or \"AB\"\n",
    "    returns True if coord lies on the forbidden ring\n",
    "    for the given kind of plaquette.\n",
    "    \"\"\"\n",
    "    r, c = coord\n",
    "\n",
    "    # ---- these three edges are common to both AB and ABC ----\n",
    "    # right edge       c = 2*n,  r in [n .. 2*n-1]\n",
    "    # left edge        c = n-1,  r in [n .. 2*n-1]\n",
    "    # bottom edge      r = 2*n, c in [n+1 .. 2*n-1]\n",
    "    if (n <= r <= 2*n-1 and c == 2*n) or \\\n",
    "       (n <= r <= 2*n-1 and c == n-1) or \\\n",
    "       (r == 2*n   and n+1 <= c <= 2*n-1):\n",
    "        return True\n",
    "\n",
    "    # ---- the only difference is the “top” segment ----\n",
    "    if kind.upper() == \"ABC\":\n",
    "        # single horizontal strip at r = n-1\n",
    "        return (r == n-1 and n <= c <= 2*n-1)\n",
    "    else:\n",
    "        # two vertical strips at c = n or c = 2*n-1\n",
    "        # for r = 1 .. n-1\n",
    "        return (1 <= r <= n-1 and (c == n or c == 2*n-1))\n",
    "\n",
    "\n",
    "def flip_one(plaq_zero, n, kind=\"ABC\"):\n",
    "    \"\"\"\n",
    "    Randomly choose (i, coord) in plaq_zero; if coord is NOT on\n",
    "    the forbidden hole‑boundary (of the given kind), flip it.\n",
    "    \"\"\"\n",
    "    plaq = copy.deepcopy(plaq_zero)\n",
    "    while True:\n",
    "        i = random.choice([i for i in range (len(plaq_zero))])\n",
    "        choices = list(plaq_zero[i].keys())\n",
    "        k = random.choice(choices)\n",
    "        if not is_on_hole_boundary(k, n, kind):\n",
    "            plaq[i][k] = 1 - plaq_zero[i][k]\n",
    "            return plaq\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.661279Z",
     "start_time": "2025-04-19T03:12:43.648279Z"
    }
   },
   "id": "6c7753e2ccca6ef",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_on_hole_boundary((1, 4), 4, kind=\"AC\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:32:32.415061Z",
     "start_time": "2025-04-19T03:32:32.395979Z"
    }
   },
   "id": "3ff13218cea6f69a",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "def initial_top_ABC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Build a list of n tensors corresponding to the top row.\n",
    "    The leftmost and rightmost are boundary incomplete (shape (2,2)),\n",
    "    while the ones in between are boundary full (shape (2,2,2)).\n",
    "    \"\"\"\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_edge_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "def seq_ABC(n, plaq_dict, plaq, p):\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_edge_tensor(m, p))  # right boundary, shape (2,2,2)\n",
    "    return tensor_list\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_initial_ABC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Contract a list of n top-boundary tensors from left to right.\n",
    "    The free vertical indices remain, and internal (horizontal) indices are contracted.\n",
    "    \"\"\"\n",
    "    # Define labels for the indices.\n",
    "    label = string.ascii_letters\n",
    "    # Initialize the tensor list.\n",
    "    tensor_list = initial_top_ABC(n, plaq_dict, plaq, p)\n",
    "    '''\n",
    "     0 - - n\n",
    "        |\n",
    "       2*n\n",
    "       to \n",
    "     0 - - n\n",
    "     1 - - n+1\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "     n-1 -- 2*n-1   \n",
    "    '''\n",
    "    # Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\n",
    "    top_term = label[0]+label[n-1]+label[2*n-2] \n",
    "    top_tensor = tensor_list[0]\n",
    "    # Middle tensors (i = 2,..., n-1): shape (2,2,2,2)\n",
    "    for i in range(1, n - 2):\n",
    "        term = label[2*n-2] + label[i] + label[n + i - 1] + label[2*n - 1]\n",
    "        output_subscript = label[:i+1] + label[n-1:n+i] + label[2*n-1]\n",
    "        einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_term = label[:i+1] + label[n-1:n+i] + label[2*n-2]\n",
    "\n",
    "    # Rightmost tensor: shape (2,2,2)\n",
    "    term = label[n - 2] + label[2*n-2] + label[2*n - 3]\n",
    "    output_subscript = label[:2*n-2]\n",
    "    einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 2])\n",
    "\n",
    "    return top_tensor\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_column_ABC(n, plaq_dict, plaq, p, top_tensor):\n",
    "    \"\"\"\n",
    "    Contract the list of n bulk tensors with the top tensor from left to right.\n",
    "         _ 2n+1\n",
    "        |\n",
    "        2n\n",
    "       -n+1\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor_list = seq_ABC(n, plaq_dict, plaq, p)\n",
    "    top_terms = label[:2*n-2]\n",
    "    term = label[n-1]  + label[2*n-2] + label[2*n - 1]\n",
    "    output_subscript = label[:n-1]+ label[2*n-1] + label[2*n-2] + label[n:2*n-2] \n",
    "    einsum_subscript = top_terms + \",\" + term + \"->\" + output_subscript\n",
    "    \n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[0])\n",
    "    top_terms = label[:n] + label[2*n-2]+ label[n:2*n-2]\n",
    "\n",
    "    for i in range(1, n - 2):\n",
    "        term = label[n+i-1] + label[2*n-2] + label[2*n - 1] + label[2*n]\n",
    "        output_subscript = label[:n+i-1] + label[2*n - 1] + label[2*n - 2]  + label[n+i:2*n-2]\n",
    "        einsum_subscript = top_terms + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_terms = label[:n+i] + label[2*n-2] + label[n+i:2*n-2]\n",
    "    term = label[2*n - 3] + label[2*n-2] + label[2*n - 1]\n",
    "    output_subscript = label[:2*n-3] + label[2*n - 1]\n",
    "    einsum_subscript = top_terms + \",\" + term + \"->\" + output_subscript\n",
    "    final_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 2])\n",
    "\n",
    "    return final_tensor\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_ladder_ABC(n, plaq_dict, plaq, p, initial_tensor):\n",
    "    \"\"\"\n",
    "    Perform a ladder contraction over n tensors.\n",
    "        | (2n)\n",
    "      - (n+1)\n",
    "      - (n+2)\n",
    "        to\n",
    "        \n",
    "        - (2n+1\n",
    "        |(2n+2)\n",
    "       -(n+2)    \n",
    "    full tensor is labelled as \n",
    "       2\n",
    "    1    3 \n",
    "      4\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor = initial_tensor\n",
    "    \n",
    "    for i in range(n - 2):\n",
    "        term1 = label[:2*n-2]\n",
    "        term2 = label[n-1] + label[2*n-2]\n",
    "        output_subscript = label[:n-1]+label[2*n-2] + label[n:2*n-2]\n",
    "        einsum_subscript = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "        tensor = jnp.einsum(einsum_subscript, tensor, corner_tensor(plaq_dict[i][plaq[i][0]], p))\n",
    "        term1 = output_subscript\n",
    "        for j in range(1, n - i - 1):\n",
    "            term2 = label[n + j - 1] + label[2*n-2] + label[2*n - 1] + label[2*n]\n",
    "            output_subscript = label[:n+j-2] + label[2*n - 1] + label [2*n] + label[n + j : 2*n-2]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][j]], p))\n",
    "            term1 = label[:n+j-1] + label[2*n-2] + label[n+j:2*n-2]\n",
    "    term1 = label[:2*n-2]\n",
    "    corner = corner_tensor(plaq_dict[n-2][plaq[n-2][0]], p)\n",
    "    term2 = label[n-1] + label[2*n-2]\n",
    "    output_subscript = label[:n-1] + label[n:2*n - 1]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "    tensor = jnp.einsum(einsum_str, tensor, corner)\n",
    "\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.692278Z",
     "start_time": "2025-04-19T03:12:43.663278Z"
    }
   },
   "id": "e40f14e99afb5ea1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.707532Z",
     "start_time": "2025-04-19T03:12:43.695278Z"
    }
   },
   "id": "9c4a9ca3f19ef13b",
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.722947Z",
     "start_time": "2025-04-19T03:12:43.711112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plaq_B_dict[0]"
   ],
   "id": "5c0eebfe9ab46535",
   "outputs": [
    {
     "data": {
      "text/plain": "{(1, 5): 0, (2, 5): 0}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.738570Z",
     "start_time": "2025-04-19T03:12:43.723947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plaq_B[0]"
   ],
   "id": "c77b0e5e471790a8",
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 5), (2, 5)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def initial_top_BC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Build a list of n tensors corresponding to the top row.\n",
    "    The leftmost and rightmost are boundary incomplete (shape (2,2)),\n",
    "    while the ones in between are boundary full (shape (2,2,2)).\n",
    "    \"\"\"\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(corner_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 4):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(incomplete_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-3]]\n",
    "    tensor_list.append(corner_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "def seq_BC(n, plaq_dict, plaq, p):\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 4):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-3]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_initial_BC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Contract a list of n top-boundary tensors from left to right.\n",
    "    The free vertical indices remain, and internal (horizontal) indices are contracted.\n",
    "    \"\"\"\n",
    "    # Define labels for the indices.\n",
    "    label = string.ascii_letters\n",
    "    # Initialize the tensor list.\n",
    "    tensor_list = initial_top_BC(n, plaq_dict, plaq, p)\n",
    "    #print(\"tensor_list:\", tensor_list)\n",
    "    # Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\n",
    "    top_term = label[0]+label[n - 2] \n",
    "    top_tensor = tensor_list[0]\n",
    "    # Middle tensors (i = 2,..., n-1): shape (2,2,2,2)\n",
    "    for i in range(1, n - 3):\n",
    "        term = label[n - 2] + label[i] + label[n - 1]\n",
    "        output_subscript = label[:i+1] + label[n - 1]\n",
    "        einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_term = label[:i+1] + label[n - 2]\n",
    "\n",
    "    # Rightmost tensor: shape (2,2,2)\n",
    "    term = label[n - 2] + label[n - 3] \n",
    "    output_subscript = label[:n-2]\n",
    "    einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 3])\n",
    "    #print(top_tensor)\n",
    "    return top_tensor\n",
    "\n",
    "def process_column_BC(n, plaq_dict, plaq, p, tensor):\n",
    "    \"\"\"\n",
    "    Process a column of tensors in the lattice.\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor_list = seq_BC(n, plaq_dict, plaq, p)\n",
    "    tensor1 = tensor\n",
    "    \n",
    "    term1 = label[:(n-2)]\n",
    "    term2 = label[0] + label[n-2] + label[n-1]\n",
    "    output_str = label[n-1]+label[n-2]+label[1:n-2] \n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[0])\n",
    "    term1 = label[0] + label[n-2] + label[1:n-2]\n",
    "    for j in range(1, n-3):\n",
    "        term2 = label[j] + label[(n-2)] + label[n-1] + label[n]\n",
    "        output_str = label[:j] + label[n-1] + label[n] + label[(j+1):(n-2)]\n",
    "        einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "        tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[j])\n",
    "        term1 = label[:j+1] + label[(n-2)] + label[(j+1):(n-2)]\n",
    "\n",
    "    term2 = label[n-3]+label[(n-2)] + label[(n-1)] \n",
    "    output_str = label[:(n-3)] + label[n-1]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[n-3])\n",
    "    return tensor1\n",
    "\n",
    "\n",
    "    \n",
    "def process_ladder_BC(n, plaq_dict, plaq, p, tensor):\n",
    "    label = string.ascii_letters\n",
    "    for i in range(n - 2):\n",
    "        term1 = label[:(n-2)]\n",
    "        term2 = label[0] + label[(n-2)]\n",
    "        output_subscript = label[n-2] + label[1:n-2]\n",
    "        einsum_subscript = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "        #print(einsum_subscript)\n",
    "        tensor = jnp.einsum(einsum_subscript, tensor, corner_tensor(plaq_dict[i][plaq[i][0]], p))\n",
    "        term1 = output_subscript\n",
    "        j = 0\n",
    "        for j in range(1, n - i - 2):\n",
    "\n",
    "            term2 = label[j] + label[(n-2)] + label[n-1] + label[n]\n",
    "            output_subscript = label[:j-1] + label[n-1] + label [n] + label[(j+1):(n-2)]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            #print(\"bulk:\", einsum_str)\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][j]], p))\n",
    "            term1 = label[:j] + label[(n-2)] + label[j+1:(n-2)]\n",
    "            \n",
    "        if i == 0:\n",
    "            term2 = label[n-2] + label[n-3]\n",
    "            output_subscript = label[:(n-2)]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            #print(\"end_first_col:\", einsum_str)\n",
    "            tensor = jnp.einsum(einsum_str, tensor, corner_tensor(plaq_dict[i][plaq[i][n-2]], p))\n",
    "            term1 = label[:(n-2)]\n",
    "        else:\n",
    "            term2 = label[j+1]+label[(n-2)]+label[n-1]+label[n]\n",
    "            output_subscript = label[:j] + label[n-1] + label [n] + label[j+2:n-2]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            #print(\"end_col:\", einsum_str)\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][n-i-2]], p))\n",
    "            term1 = label[:(n-2)]\n",
    "\n",
    "    term2 = label[0] + label[(n-2)]\n",
    "    output_subscript = label[n-2]+label[1:(n-2)]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "    #print(einsum_str)\n",
    "    tensor = jnp.einsum(einsum_str, tensor, corner_tensor(plaq_dict[n-2][plaq[n-2][0]], p))\n",
    "\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.769424Z",
     "start_time": "2025-04-19T03:12:43.739653Z"
    }
   },
   "id": "86d2609092603ed2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def initial_top_AC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Build a list of n tensors corresponding to the top row.\n",
    "    The leftmost and rightmost are boundary incomplete (shape (2,2)),\n",
    "    while the ones in between are boundary full (shape (2,2,2)).\n",
    "    \"\"\"\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(inner_corner_tensor(m, p))  # left boundary, shape (2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(inner_edge_tensor(m, p))  # middle plaquettes, shape (2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_corner_tensor(m, p))  # right boundary, shape (2,2)\n",
    "    return tensor_list\n",
    "\n",
    "def seq_AC(n, plaq_dict, plaq, p):\n",
    "    tensor_list = []\n",
    "    \n",
    "    m = plaq_dict[plaq[0]]\n",
    "    tensor_list.append(incomplete_tensor(m, p))  # left boundary, shape (2,2,2)\n",
    "    for i in range(n - 3):\n",
    "        m = plaq_dict[plaq[i+1]]\n",
    "        tensor_list.append(full_tensor(m, p))  # middle plaquettes, shape (2,2,2,2)\n",
    "    m = plaq_dict[plaq[n-2]]\n",
    "    tensor_list.append(inner_edge_tensor(m, p))  # right boundary, shape (2,2,2)\n",
    "    return tensor_list\n",
    "\n",
    "#@partial(jax.jit, static_argnums=(0,))\n",
    "def process_initial_AC(n, plaq_dict, plaq, p):\n",
    "    \"\"\"\n",
    "    Contract a list of n top-boundary tensors from left to right.\n",
    "    The free vertical indices remain, and internal (horizontal) indices are contracted.\n",
    "    \"\"\"\n",
    "    # Define labels for the indices.\n",
    "    label = string.ascii_letters\n",
    "    # Initialize the tensor list.\n",
    "    tensor_list = initial_top_AC(n, plaq_dict, plaq, p)\n",
    "\n",
    "    # Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\n",
    "    top_term = label[0]+label[n - 1] \n",
    "    top_tensor = tensor_list[0]\n",
    "    # Middle tensors (i = 2,..., n-1): shape (2,2,2,2)\n",
    "    for i in range(1, n - 2):\n",
    "        term = label[n - 1] + label[i] + label[n]\n",
    "        output_subscript = label[:i+1] + label[n]\n",
    "        einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "        top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[i])\n",
    "        top_term = label[:i+1] + label[n - 1]\n",
    "\n",
    "    # Rightmost tensor: shape (2,2,2)\n",
    "    term = label[n - 1] + label[n - 2] \n",
    "    output_subscript = label[:n-1]\n",
    "    einsum_subscript = top_term + \",\" + term + \"->\" + output_subscript\n",
    "    top_tensor = jnp.einsum(einsum_subscript, top_tensor, tensor_list[n - 2])\n",
    "\n",
    "    return top_tensor\n",
    "\n",
    "def process_column_AC(n, plaq_dict, plaq, p, tensor):\n",
    "    \"\"\"\n",
    "    Process a column of tensors in the lattice.\n",
    "    \"\"\"\n",
    "    label = string.ascii_letters\n",
    "    tensor_list = seq_AC(n, plaq_dict, plaq, p)\n",
    "    tensor1 = tensor\n",
    "    \n",
    "    term1 = label[:(n-1)]\n",
    "    term2 = label[0] + label[n-1] + label[n]\n",
    "    output_str = label[n]+label[n-1]+label[1:n-1] \n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[0])\n",
    "    term1 = label[0] + label[n-1] + label[1:n-1]\n",
    "\n",
    "    for j in range(1, n-2):\n",
    "        term2 = label[j] + label[(n-1)] + label[n] + label[n+1]\n",
    "        output_str = label[:j] + label[n] + label[n+1] + label[(j+1):(n-1)]\n",
    "        einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "        tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[j])\n",
    "        term1 = label[:j+1] + label[(n-1)] + label[(j+1):(n-1)]\n",
    "    term2 = label[n-2]+label[(n-1)] + label[n] \n",
    "    output_str = label[:(n-2)] + label[n]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor_list[n-2])\n",
    "    return tensor1\n",
    "    \n",
    "def process_ladder_AC(n, plaq_dict, plaq, p, tensor):\n",
    "    # Only here the plaq_dict is a list of dict.\n",
    "    label = string.ascii_letters\n",
    "    for i in range(n - 2):\n",
    "        term1 = label[:(n-1)]\n",
    "        term2 = label[0] + label[(n-1)]\n",
    "        output_subscript = label[n-1] + label[1:n-1]\n",
    "        einsum_subscript = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "        tensor = jnp.einsum(einsum_subscript, tensor, corner_tensor(plaq_dict[i][plaq[i][0]], p))\n",
    "        term1 = output_subscript\n",
    "        for j in range(1, n - i - 1):\n",
    "            term2 = label[j] + label[n-1] + label[n] + label[n+1]\n",
    "            output_subscript = label[:j-1] + label[n+1] + label [n] + label[(j+1):(n-1)]\n",
    "            einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "            tensor = jnp.einsum(einsum_str, tensor, full_tensor(plaq_dict[i][plaq[i][j]], p))\n",
    "            term1 = label[:j] + label[(n-1)] + label[j+1:(n-1)]\n",
    "    term1 = label[:(n-1)]\n",
    "    term2 = label[0] + label[n-1]\n",
    "    output_subscript = label[n-1]+label[1:(n-1)]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "    tensor = jnp.einsum(einsum_str, tensor, corner_tensor(plaq_dict[n-2][plaq[n-2][0]], p))\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def last_contraction_AC(n, tensor):\n",
    "    label = string.ascii_letters\n",
    "    term1 = label[:(n-1)]\n",
    "    term2 = label[0] + label[n-1]\n",
    "    output_subscript = label[n-1]+label[1:(n-1)]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "    tensor = jnp.einsum(einsum_str, tensor, inner_corner_tensor(0, p))\n",
    "    term1 = output_subscript\n",
    "    for i in range(1, n-2):\n",
    "        term2 = label[n-1]+label[i]+label[n]\n",
    "        output_subscript = label[n]+label[i+1:n-1]\n",
    "        einsum_str = term1 + \",\" + term2 + \"->\" + output_subscript\n",
    "        tensor = jnp.einsum(einsum_str, tensor, inner_edge_tensor(0, p))\n",
    "        term1 = label[n-1]+label[i+1:n-1]\n",
    "    return jnp.sum(tensor*inner_corner_tensor(0, p))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.800639Z",
     "start_time": "2025-04-19T03:12:43.771147Z"
    }
   },
   "id": "665e521c2f89e0ac",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.815780Z",
     "start_time": "2025-04-19T03:12:43.802642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def n_tensor_product_shape_2(n, p):\n",
    "    vec = jnp.sqrt(jnp.array([1 - p, p]))\n",
    "    result = vec\n",
    "    for _ in range(n - 1):\n",
    "        result = jnp.tensordot(result, vec, axes=0)\n",
    "    return result"
   ],
   "id": "f5f599b5e6a63a13",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "def Pr_m_B_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor = process_initial_BC(n, plaq_dict[0], plaq[0], p)\n",
    "    for i in range(1, n-2):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
    "    Pr_m_B = jnp.sum(ini_tensor)\n",
    "    return Pr_m_B\n",
    "\n",
    "def Pr_m_C_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor1 = process_initial_BC(n, plaq_dict[0], plaq[0], p)\n",
    "    for i in range(1, n):\n",
    "        ini_tensor1 = process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor1)\n",
    "    ini_tensor1 = process_ladder_BC(n, plaq_dict[n:2*n-1], plaq[n:2*n-1], p, ini_tensor1)\n",
    "\n",
    "    ini_tensor2 = process_initial_BC(n, plaq_dict[2*n-1], plaq[2*n-1], p)\n",
    "    for i in range(n-1):\n",
    "        ini_tensor2 = process_column_BC(n, plaq_dict[2*n+i], plaq[2*n+i], p, ini_tensor2)\n",
    "    ini_tensor2 = process_ladder_BC(n, plaq_dict[3*n-1:4*n-2], plaq[3*n-1:4*n-2], p, ini_tensor2)\n",
    "    revision_vec = n_tensor_product_shape_2(n-2, p)\n",
    "    Pr_m_C = jnp.sum(ini_tensor1*revision_vec)*jnp.sum(ini_tensor2*revision_vec)\n",
    "    return Pr_m_C\n",
    "\n",
    "def Pr_m_BC_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor = process_initial_BC(n, plaq_dict[0], plaq[0], p)\n",
    "    #print(\"ini:\", ini_tensor)\n",
    "    for i in range(1, n):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
    "        #print(\"col:\", ini_tensor)\n",
    "    ini_tensor = process_ladder_BC(n, plaq_dict[n:2*n-1], plaq[n:2*n-1], p, ini_tensor)\n",
    "    #print(\"ladder:\", ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[2*n-1+i], plaq[2*n-1+i], p, ini_tensor)\n",
    "        #print(\"col:\", ini_tensor)\n",
    "    ini_tensor = process_ladder_BC(n, plaq_dict[3*n-1:4*n-2], plaq[3*n-1:4*n-2], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_BC(n, plaq_dict[4*n-2+i], plaq[4*n-2+i], p, ini_tensor)\n",
    "    \n",
    "    revision_vec = n_tensor_product_shape_2(n-2, p)\n",
    "    Pr_m_BC = jnp.sum(ini_tensor*revision_vec)\n",
    "    \n",
    "    return Pr_m_BC\n",
    "\n",
    "def Pr_m_AC_func(n, plaq_dict, plaq, p):\n",
    "    ini_tensor = process_initial_AC(n, plaq_dict[0], plaq[0], p)\n",
    "    #print(\"ini_before_ladder:\", ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[1:n], plaq[1:n], p, ini_tensor)\n",
    "    #print(\"ini_after_ladder:\", ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_AC(n, plaq_dict[n+i], plaq[n+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[2*n:3*n-1], plaq[2*n:3*n-1], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_AC(n, plaq_dict[3*n-1+i], plaq[3*n-1+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[4*n-1:5*n-2], plaq[4*n-1:5*n-2], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_AC(n, plaq_dict[5*n-2+i], plaq[5*n-2+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_AC(n, plaq_dict[6*n-2:7*n-3], plaq[6*n-2:7*n-3], p, ini_tensor)\n",
    "    Pr_m_AC = last_contraction_AC(n, ini_tensor)\n",
    "    \n",
    "    return Pr_m_AC\n",
    "\n",
    "def Pr_m_ABC_func(n, plaq_dict, plaq, p):\n",
    "    label = string.ascii_letters\n",
    "    ini_tensor = process_initial_ABC(n, plaq_dict[0], plaq[0], p)\n",
    "    for i in range(1, n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[n:2*n-1], plaq[n:2*n-1], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[2*n-1+i], plaq[2*n-1+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[3*n-1:4*n-2], plaq[3*n-1:4*n-2], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[4*n-2+i], plaq[4*n-2+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[5*n-2:6*n-3], plaq[5*n-2:6*n-3], p, ini_tensor)\n",
    "    for i in range(n):\n",
    "        ini_tensor = process_column_ABC(n, plaq_dict[6*n-3+i], plaq[6*n-3+i], p, ini_tensor)\n",
    "    ini_tensor = process_ladder_ABC(n, plaq_dict[7*n-3:8*n-4], plaq[7*n-3:8*n-4], p, ini_tensor)\n",
    "    einsum_str = label[:n-1]+label[:n-1] + \"->\" \n",
    "    return jnp.einsum(einsum_str, ini_tensor)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.847331Z",
     "start_time": "2025-04-19T03:12:43.818099Z"
    }
   },
   "id": "916e55a54ab69dcc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "plaq_BC_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.862973Z",
     "start_time": "2025-04-19T03:12:43.849415Z"
    }
   },
   "id": "24819dbc9d728256",
   "outputs": [
    {
     "data": {
      "text/plain": "[{(7, 1): 0, (7, 2): 0},\n {(6, 1): 0, (6, 2): 0},\n {(5, 1): 0, (5, 2): 0},\n {(4, 1): 0, (4, 2): 0},\n {(3, 1): 0, (3, 2): 0, (3, 3): 0},\n {(2, 2): 0, (2, 3): 0},\n {(1, 3): 0},\n {(1, 4): 0, (2, 4): 0},\n {(1, 5): 0, (2, 5): 0},\n {(1, 6): 0, (2, 6): 0},\n {(1, 7): 0, (2, 7): 0},\n {(1, 8): 0, (2, 8): 0, (3, 8): 0},\n {(2, 9): 0, (3, 9): 0},\n {(3, 10): 0},\n {(4, 10): 0, (4, 9): 0},\n {(5, 10): 0, (5, 9): 0},\n {(6, 10): 0, (6, 9): 0},\n {(7, 10): 0, (7, 9): 0}]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def metropolis_step(n, plaq_dict, Pr_func, plaq, p, num_samples, kind):\n",
    "    \"\"\"\n",
    "    Perform num_samples Metropolis updates on plaq_dict.\n",
    "    \n",
    "    Args:\n",
    "      n             : system size\n",
    "      plaq_dict     : current configuration (dict-of-dicts)\n",
    "      Pr_func       : function signature Pr = Pr_func(n, config, plaq, p)\n",
    "      plaq          : any auxiliary data needed by Pr_func\n",
    "      p             : model parameter\n",
    "      num_samples   : how many proposed flips to attempt\n",
    "\n",
    "    Returns:\n",
    "      plaq_dict_new : updated configuration after all steps\n",
    "      w_list        : list of log‑probabilities at each step (length num_samples+1)\n",
    "    \"\"\"\n",
    "    w_list = []\n",
    "    Pr0 = Pr_func(n, plaq_dict, plaq, p)\n",
    "    w_list.append(jnp.log(Pr0))\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        if kind in (\"C\", \"BC\"):\n",
    "            candidate = flip_one_free(plaq_dict)\n",
    "        else:\n",
    "            candidate = flip_one(plaq_dict, n, kind)\n",
    "        Pr  = Pr_func(n, candidate, plaq, p)\n",
    "        # accept with Metropolis criterion\n",
    "        if random.random() < (Pr / Pr0):\n",
    "            #print(\"accept\")\n",
    "            plaq_dict = candidate\n",
    "            Pr0       = Pr\n",
    "        w_list.append(jnp.log(Pr0))\n",
    "\n",
    "    return plaq_dict, w_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:43.878239Z",
     "start_time": "2025-04-19T03:12:43.863972Z"
    }
   },
   "id": "af0f37ea7f6040a3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "p = 0.5\n",
    "num_samples = 20\n",
    "keyC, keyBC, keyAC, keyABC = jax.random.PRNGKey(0), jax.random.PRNGKey(1), jax.random.PRNGKey(2), jax.random.PRNGKey(3)\n",
    "w_c, w_bc, w_ac, w_abc = [], [], [], []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:12:44.066609Z",
     "start_time": "2025-04-19T03:12:43.986864Z"
    }
   },
   "id": "cc983b5989fec1ca",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "plaq_C_dict,  w_c = metropolis_step(n, plaq_C_dict, Pr_m_C_func, plaq_C, p, num_samples, \"C\")\n",
    "plaq_BC_dict, w_bc = metropolis_step(n, plaq_BC_dict, Pr_m_BC_func, plaq_BC, p, num_samples, \"BC\")\n",
    "plaq_AC_dict, w_ac = metropolis_step(n, plaq_AC_dict, Pr_m_AC_func, plaq_AC, p, num_samples, \"AC\")\n",
    "plaq_ABC_dict, w_abc = metropolis_step(n, plaq_ABC_dict, Pr_m_ABC_func, plaq_ABC, p, num_samples, \"ABC\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:13:38.989460Z",
     "start_time": "2025-04-19T03:12:45.607065Z"
    }
   },
   "id": "40a6bfb9f51dea32",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "-jnp.sum(jnp.array(w_ac) + jnp.array(w_bc) - jnp.array(w_abc) - jnp.array(w_c))/num_samples/jnp.log(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-19T03:13:39.160928Z",
     "start_time": "2025-04-19T03:13:38.991880Z"
    }
   },
   "id": "d4c0ce426c6edde9",
   "outputs": [
    {
     "data": {
      "text/plain": "Array(2.1, dtype=float64)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "jnp.sum(jnp.array(w_ac) + jnp.array(w_bc) - jnp.array(w_abc) - jnp.array(w_b))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-18T06:11:02.846898Z",
     "start_time": "2025-04-18T06:11:02.827804Z"
    }
   },
   "id": "8270fa3a206ed7dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4c934bc70a100d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plaq_dict_m [{(1, 6): 0, (2, 6): 0, (3, 6): 0}, {(1, 7): 0, (2, 7): 0, (3, 7): 0}, {(1, 8): 0, (2, 8): 0, (3, 8): 0}]\n"
     ]
    },
    {
     "ename": "TracerBoolConversionError",
     "evalue": "Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function step at C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_32880\\2635678145.py:23 for scan. This concrete value was not available in Python because it depends on the value of the argument carry[0][0][(1, 6)].\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTracerBoolConversionError\u001B[0m                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[107], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m AC_sampler \u001B[38;5;241m=\u001B[39m make_metropolis(Pr_m_AC_func, plaq_AC, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAC\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m ABC_sampler \u001B[38;5;241m=\u001B[39m make_metropolis(Pr_m_ABC_func, plaq_ABC, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mABC\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 11\u001B[0m plaq_B_dict,  w_b  \u001B[38;5;241m=\u001B[39m \u001B[43mB_sampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq_B_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeyB\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m plaq_BC_dict, w_bc \u001B[38;5;241m=\u001B[39m BC_sampler(n, plaq_BC_dict, p, num_samples, keyBC)\n\u001B[0;32m     13\u001B[0m plaq_AC_dict, w_ac \u001B[38;5;241m=\u001B[39m AC_sampler(n, plaq_AC_dict, p, num_samples, keyAC)\n",
      "Cell \u001B[1;32mIn[106], line 39\u001B[0m, in \u001B[0;36mmake_metropolis.<locals>.metropolis_step\u001B[1;34m(n, plaq_dict, p, num_samples, keym)\u001B[0m\n\u001B[0;32m     36\u001B[0m     w \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mlog(new_Pr)\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (new_config, new_Pr), w\n\u001B[1;32m---> 39\u001B[0m (final_config, _), w_scan \u001B[38;5;241m=\u001B[39m \u001B[43mlax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mplaq_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPr0\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeym\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m final_config, jnp\u001B[38;5;241m.\u001B[39mconcatenate((jnp\u001B[38;5;241m.\u001B[39marray([w0]), w_scan))\n",
      "    \u001B[1;31m[... skipping hidden 9 frame]\u001B[0m\n",
      "Cell \u001B[1;32mIn[106], line 30\u001B[0m, in \u001B[0;36mmake_metropolis.<locals>.metropolis_step.<locals>.step\u001B[1;34m(carry, r_key)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     29\u001B[0m     candidate \u001B[38;5;241m=\u001B[39m flip_one(config, n, kind)\n\u001B[1;32m---> 30\u001B[0m Pr_cand \u001B[38;5;241m=\u001B[39m \u001B[43mPr_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcandidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# accept with Metropolis criterion\u001B[39;00m\n\u001B[0;32m     32\u001B[0m accept \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(k2) \u001B[38;5;241m<\u001B[39m (Pr_cand \u001B[38;5;241m/\u001B[39m Pr_prev)\n",
      "Cell \u001B[1;32mIn[104], line 2\u001B[0m, in \u001B[0;36mPr_m_B_func\u001B[1;34m(n, plaq_dict, plaq, p)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mPr_m_B_func\u001B[39m(n, plaq_dict, plaq, p):\n\u001B[1;32m----> 2\u001B[0m     ini_tensor \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_initial_BC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m      4\u001B[0m         ini_tensor \u001B[38;5;241m=\u001B[39m process_column_BC(n, plaq_dict[i], plaq[i], p, ini_tensor)\n",
      "Cell \u001B[1;32mIn[98], line 39\u001B[0m, in \u001B[0;36mprocess_initial_BC\u001B[1;34m(n, plaq_dict, plaq, p)\u001B[0m\n\u001B[0;32m     37\u001B[0m label \u001B[38;5;241m=\u001B[39m string\u001B[38;5;241m.\u001B[39mascii_letters\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Initialize the tensor list.\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m tensor_list \u001B[38;5;241m=\u001B[39m \u001B[43minitial_top_BC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Left boundary tensor: shape (2,2) → assign indices: [bottom_label[0], virtual_label[0]]\u001B[39;00m\n\u001B[0;32m     42\u001B[0m top_term \u001B[38;5;241m=\u001B[39m label[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m+\u001B[39mlabel[n \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m] \n",
      "Cell \u001B[1;32mIn[98], line 10\u001B[0m, in \u001B[0;36minitial_top_BC\u001B[1;34m(n, plaq_dict, plaq, p)\u001B[0m\n\u001B[0;32m      7\u001B[0m tensor_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      9\u001B[0m m \u001B[38;5;241m=\u001B[39m plaq_dict[plaq[\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m---> 10\u001B[0m tensor_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43mcorner_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m)  \u001B[38;5;66;03m# left boundary, shape (2,2)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m4\u001B[39m):\n\u001B[0;32m     12\u001B[0m     m \u001B[38;5;241m=\u001B[39m plaq_dict[plaq[i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m]]\n",
      "File \u001B[1;32m~\\PycharmProjects\\UIUC_test\\util.py:416\u001B[0m, in \u001B[0;36mcorner_tensor\u001B[1;34m(m, p)\u001B[0m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcorner_tensor\u001B[39m(m, p):\n\u001B[0;32m    415\u001B[0m     tensor_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 416\u001B[0m     Q \u001B[38;5;241m=\u001B[39m \u001B[43mQ_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    417\u001B[0m     T \u001B[38;5;241m=\u001B[39m T_tensor(p)\n\u001B[0;32m    418\u001B[0m     bT \u001B[38;5;241m=\u001B[39m boundary_T_tensor(p)\n",
      "File \u001B[1;32m~\\PycharmProjects\\UIUC_test\\util.py:370\u001B[0m, in \u001B[0;36mQ_tensor\u001B[1;34m(m)\u001B[0m\n\u001B[0;32m    368\u001B[0m                 parity \u001B[38;5;241m=\u001B[39m (s1 \u001B[38;5;241m+\u001B[39m s2 \u001B[38;5;241m+\u001B[39m s3 \u001B[38;5;241m+\u001B[39m s4) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    369\u001B[0m                 \u001B[38;5;66;03m# If parity matches the anyon measurement, set entry to 1.\u001B[39;00m\n\u001B[1;32m--> 370\u001B[0m                 value \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mparity\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    371\u001B[0m                 Q \u001B[38;5;241m=\u001B[39m Q\u001B[38;5;241m.\u001B[39mat[s1, s2, s3, s4]\u001B[38;5;241m.\u001B[39mset(value)\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Q\n",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\UIUC_test\\.venv\\lib\\site-packages\\jax\\_src\\core.py:1517\u001B[0m, in \u001B[0;36mconcretization_function_error.<locals>.error\u001B[1;34m(self, arg)\u001B[0m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21merror\u001B[39m(\u001B[38;5;28mself\u001B[39m, arg):\n\u001B[1;32m-> 1517\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m TracerBoolConversionError(arg)\n",
      "\u001B[1;31mTracerBoolConversionError\u001B[0m: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function step at C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_32880\\2635678145.py:23 for scan. This concrete value was not available in Python because it depends on the value of the argument carry[0][0][(1, 6)].\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
     ]
    }
   ],
   "source": [
    "p = 0.1\n",
    "num_samples = 3\n",
    "keyB, keyBC, keyAC, keyABC = jax.random.PRNGKey(0), jax.random.PRNGKey(1), jax.random.PRNGKey(2), jax.random.PRNGKey(3)\n",
    "w_b, w_bc, w_ac, w_abc = [], [], [], []\n",
    "\n",
    "B_sampler = make_metropolis(Pr_m_B_func, plaq_B, \"B\")\n",
    "BC_sampler = make_metropolis(Pr_m_BC_func, plaq_BC, \"BC\")\n",
    "AC_sampler = make_metropolis(Pr_m_AC_func, plaq_AC, \"AC\")\n",
    "ABC_sampler = make_metropolis(Pr_m_ABC_func, plaq_ABC, \"ABC\")\n",
    "\n",
    "plaq_B_dict,  w_b  = B_sampler(n, plaq_B_dict, p, num_samples, keyB)\n",
    "plaq_BC_dict, w_bc = BC_sampler(n, plaq_BC_dict, p, num_samples, keyBC)\n",
    "plaq_AC_dict, w_ac = AC_sampler(n, plaq_AC_dict, p, num_samples, keyAC)\n",
    "plaq_ABC_dict, w_abc = ABC_sampler(n, plaq_ABC_dict, p, num_samples, keyABC)\n",
    "\n",
    "CMI = jnp.sum(jnp.array(w_ac) + jnp.array(w_bc) - jnp.array(w_abc) - jnp.array(w_b))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T22:18:57.290800Z",
     "start_time": "2025-04-17T22:18:57.053256Z"
    }
   },
   "id": "8ec102584edf806a",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Array([[[[0., 1.],\n         [1., 0.]],\n\n        [[1., 0.],\n         [0., 1.]]],\n\n\n       [[[1., 0.],\n         [0., 1.]],\n\n        [[0., 1.],\n         [1., 0.]]]], dtype=float64)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_tensor(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T22:27:20.276883Z",
     "start_time": "2025-04-17T22:27:20.258014Z"
    }
   },
   "id": "9ad4ba43ef5d894d",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[[(1, 6), (2, 6), (3, 6)], [(1, 7), (2, 7), (3, 7)], [(1, 8), (2, 8), (3, 8)]]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaq_B"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T22:12:29.747004Z",
     "start_time": "2025-04-17T22:12:29.733050Z"
    }
   },
   "id": "433fe3e60c23e1a7",
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = 0\n",
    "'''\n",
    "def make_metropolis(Pr_func, plaq, kind):\n",
    "    #@partial(jax.jit, static_argnums=(0, ))\n",
    "    def metropolis_step(n, plaq_dict, p, num_samples, keym):\n",
    "        \"\"\"\n",
    "        Perform `num_samples` Metropolis updates on `plaq_dict`.\n",
    "\n",
    "        Args:\n",
    "          n             : system size\n",
    "          plaq_dict     : current configuration (dict-of-dicts)\n",
    "          Pr_func       : function signature Pr = Pr_func(n, config, plaq, p)\n",
    "          plaq          : any auxiliary data needed by Pr_func\n",
    "          p             : model parameter\n",
    "          num_samples   : how many proposed flips to attempt\n",
    "\n",
    "        Returns:\n",
    "          plaq_dict_new : updated configuration after all steps\n",
    "          w_list        : list of log‑probabilities at each step (length num_samples+1)\n",
    "        \"\"\"\n",
    "        print(\"plaq_dict_m\", plaq_dict)\n",
    "        Pr0 = Pr_func(n, plaq_dict, plaq, p)\n",
    "        w0 = jnp.log(Pr0)\n",
    "\n",
    "        def step(carry, r_key):\n",
    "            config, Pr_prev = carry\n",
    "            k1, k2 = jax.random.split(r_key)\n",
    "            if kind in (\"B\", \"BC\"):\n",
    "                candidate = flip_one_free(config)\n",
    "            else:\n",
    "                candidate = flip_one(config, n, kind)\n",
    "            Pr_cand = Pr_func(n, candidate, plaq, p)\n",
    "            # accept with Metropolis criterion\n",
    "            accept = jax.random.uniform(k2) < (Pr_cand / Pr_prev)\n",
    "            new_config = lax.select(accept, candidate, config)\n",
    "            new_Pr = lax.select(accept, Pr_cand, Pr_prev)\n",
    "\n",
    "            w = jnp.log(new_Pr)\n",
    "            return (new_config, new_Pr), w\n",
    "\n",
    "        (final_config, _), w_scan = lax.scan(step, (plaq_dict, Pr0), jax.random.split(keym, num_samples))\n",
    "\n",
    "        return final_config, jnp.concatenate((jnp.array([w0]), w_scan))\n",
    "    return metropolis_step\n",
    "'''\n",
    "b = 0"
   ],
   "id": "c4af85b09e9d0a6c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "def H_B_tensor(n, plaq, p):\n",
    "    label = string.ascii_letters\n",
    "    tensor1 = incomplete_tensor(plaq_dict[plaq[0, 0]], p)\n",
    "    term1 = label[0] + label[n - 2] + label[2*(n-2)]\n",
    "    for i in range(n-4):\n",
    "        tensor2 = full_tensor(plaq_dict[plaq[0, i+1]], p)\n",
    "        term2 = label[i+1] + label[2*(n-2)]  + label[n - 2 + i + 1] + label[2*(n-2) + 1]\n",
    "        output_str = label[:i+1] + label[n-2:n+i+2] + label[2*(n-2)+1]\n",
    "        einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "        tensor1 = jnp.einsum(einsum_str, tensor1, tensor2)\n",
    "        term1 = label[:i+1] + label[n-2:n+i+2] + label[2*(n-2)]\n",
    "    tensor2 = incomplete_tensor(plaq_dict[plaq[0, n-3]])\n",
    "    term2 = label[n-3] + label[2*(n-2)] + label[2*(n-2) - 1]\n",
    "    output_str = label[:2*(n-2)]\n",
    "    einsum_str = term1 + \",\" + term2 + \"->\" + output_str\n",
    "    tensor1 = jnp.einsum(einsum_str, tensor1, tensor2)\n",
    "    for i in range(1, n):\n",
    "        tensor1 = process_column(n, plaq[i], p, tensor1)\n",
    "    return tensor1\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ebdc9fa615a3de9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "all_plaq = list(chain(\n",
    "    ((r, c) for r in range(1, n-1) for c in range(n, 2*n)), # top middle\n",
    "    ((2*n + r, c) for r in range(1, n-1) for c in range(n, 2*n)),  # bottom middle\n",
    "    ((r, c) for r in range(n, 2*n) for c in range(1, n-1)),\n",
    "    ((r, 2*n+c) for r in range(n, 2*n) for c in range(1, n-1)),\n",
    "    ((r, n-r+c) for r in range(n) for c in range(r)),\n",
    "    ((r, 2*n+c) for r in range(n) for c in range(r)),\n",
    "    ((2*n+r, c) for c in range(n) for r in range(c)),  \n",
    "    ((2*n+r, 2*n+c) for c in range(n) for r in range(n-c-1)),\n",
    "    ((n-1, n+c) for c in range(n)),\n",
    "    ((2*n, n+c) for c in range(n)),\n",
    "    ((n+r, n-1) for r in range(n)),\n",
    "    ((n+r, 2*n) for r in range(n)),\n",
    "))\n",
    "plaq_dict = {key: 0. for key in all_plaq}\n",
    "\n",
    "print(\"all_plaq:\", all_plaq)\n",
    "def region_plaquettes(regionEdges, all_plaq):\n",
    "    \"\"\"\n",
    "    For a given set of allowed edges (regionE\n",
    "    dges), return the list of plaquettes\n",
    "    (by their top-left coordinate) that are partially contained in the region.\n",
    "    \"\"\"\n",
    "    plaq = []\n",
    "    for (r, c) in all_plaq:\n",
    "        edges = [((r, c), 'H'),\n",
    "                 ((r+1, c), 'H'),\n",
    "                 ((r, c), 'V'),\n",
    "                 ((r, c+1), 'V')]\n",
    "        if all(e in regionEdges for e in edges):\n",
    "            plaq.append((r, c))\n",
    "    return plaq\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ee5dcac202c32e2",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
